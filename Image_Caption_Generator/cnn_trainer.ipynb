{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c12aaab-a62c-4a42-bce4-484af78a7065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 17:20:18.336027: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-01 17:20:18.345491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743508218.358547   29601 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743508218.362541   29601 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-01 17:20:18.375482: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, initializers, callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ee63d1-528e-4d74-bb27-d979cebe5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = image / 255.0  # Normalize\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea3527e-ccb5-46d6-b977-c354a070070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Custom VGG16 Model\n",
    "def build_vgg16(num_classes):\n",
    "    model = models.Sequential([\n",
    "        # Block 1\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                      kernel_initializer=initializers.GlorotUniform(), input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Block 2\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Block 3\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Block 4\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Block 5\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69dcdd0a-b802-4786-9e6d-5a795070bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMG_SIZE = 64  # Tiny ImageNet image size\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100  # Increased to 100\n",
    "NUM_CLASSES = 200  \n",
    "LEARNING_RATE = 1e-4  # Adjusted for better training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f82669fe-b981-4673-9877-52db11422872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 200 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743508224.128340   29601 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4143 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"tiny-imagenet-200/train\",\n",
    "    label_mode=\"int\",\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ").map(preprocess_image).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8607cc11-f79c-40ac-9531-f0b884a60714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"tiny-imagenet-200/val\",  # Structured validation folder\n",
    "    label_mode=\"int\",\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ").map(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6def64b-2133-4a78-8550-03258645ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model = build_vgg16(NUM_CLASSES)\n",
    "\n",
    "# compile with adam\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# compile with sgd\n",
    "#lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#    initial_learning_rate=0.01, decay_steps=10000, decay_rate=0.9\n",
    "#)\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "#model.compile(optimizer=tf.keras.optimizers.SGD(momentum=0.9, learning_rate=0.01),\n",
    "#            loss=\"sparse_categorical_crossentropy\",\n",
    "#              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c0859a-638c-4034-83d6-41b912616921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41de7a15-1638-4df7-a4b9-271c7ba17be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f31892-fb74-485a-9d04-07eff494a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"cnn_model_{epoch:02d}.keras\",  # Save model with epoch number in filename and .keras extension\n",
    "    save_best_only=True,  # Set to True to save only the best model (based on validation loss/accuracy)\n",
    "    save_freq='epoch',  # Save after every epoch\n",
    "    verbose=1  # Print a message when the model is saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b577e-079e-4427-abb5-0977dea2615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743508822.051350   29709 service.cc:148] XLA service 0x7a8cb8002540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743508822.051371   29709 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2025-04-01 17:30:22.158542: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743508822.796941   29709 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-04-01 17:30:23.612341: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4639', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2025-04-01 17:30:23.996341: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4639', 752 bytes spill stores, 784 bytes spill loads\n",
      "\n",
      "2025-04-01 17:30:24.140179: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4639', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "2025-04-01 17:30:24.417200: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5743', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2025-04-01 17:30:24.613855: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5743', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/1563\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:25:08\u001b[0m 17s/step - accuracy: 0.0000e+00 - loss: 6.9562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743508833.854821   29709 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1083/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 103ms/step - accuracy: 0.0245 - loss: 5.2886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 17:32:26.957306: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4639', 368 bytes spill stores, 368 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.0315 - loss: 5.1552"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 17:33:25.208242: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_391', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-04-01 17:33:25.705139: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_398_0', 248 bytes spill stores, 248 bytes spill loads\n",
      "\n",
      "2025-04-01 17:33:25.924162: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_391', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "2025-04-01 17:33:26.136179: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_398', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-04-01 17:33:33.834429: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_398_0', 248 bytes spill stores, 248 bytes spill loads\n",
      "\n",
      "2025-04-01 17:33:33.855383: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_391', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 6.72190, saving model to cnn_model_01.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 117ms/step - accuracy: 0.0315 - loss: 5.1549 - val_accuracy: 0.0017 - val_loss: 6.7219\n",
      "Epoch 2/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.1176 - loss: 4.1238\n",
      "Epoch 2: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 109ms/step - accuracy: 0.1176 - loss: 4.1237 - val_accuracy: 0.0111 - val_loss: 7.1339\n",
      "Epoch 3/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.1893 - loss: 3.6338\n",
      "Epoch 3: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 110ms/step - accuracy: 0.1893 - loss: 3.6338 - val_accuracy: 0.0066 - val_loss: 7.8415\n",
      "Epoch 4/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.2468 - loss: 3.2743\n",
      "Epoch 4: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 110ms/step - accuracy: 0.2468 - loss: 3.2743 - val_accuracy: 0.0057 - val_loss: 8.3354\n",
      "Epoch 5/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.3072 - loss: 2.9373\n",
      "Epoch 5: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 110ms/step - accuracy: 0.3072 - loss: 2.9373 - val_accuracy: 0.0052 - val_loss: 8.9662\n",
      "Epoch 6/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.3589 - loss: 2.6535\n",
      "Epoch 6: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 110ms/step - accuracy: 0.3589 - loss: 2.6535 - val_accuracy: 0.0109 - val_loss: 8.6873\n",
      "Epoch 7/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4225 - loss: 2.3500\n",
      "Epoch 7: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 110ms/step - accuracy: 0.4225 - loss: 2.3500 - val_accuracy: 0.0075 - val_loss: 10.0468\n",
      "Epoch 8/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.4774 - loss: 2.0685\n",
      "Epoch 8: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 112ms/step - accuracy: 0.4774 - loss: 2.0685 - val_accuracy: 0.0053 - val_loss: 10.5148\n",
      "Epoch 9/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5443 - loss: 1.7620\n",
      "Epoch 9: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 111ms/step - accuracy: 0.5443 - loss: 1.7621 - val_accuracy: 0.0056 - val_loss: 11.7892\n",
      "Epoch 10/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6060 - loss: 1.4846\n",
      "Epoch 10: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 109ms/step - accuracy: 0.6060 - loss: 1.4846 - val_accuracy: 0.0037 - val_loss: 13.3659\n",
      "Epoch 11/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.6646 - loss: 1.2325\n",
      "Epoch 11: val_loss did not improve from 6.72190\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 112ms/step - accuracy: 0.6646 - loss: 1.2325 - val_accuracy: 0.0051 - val_loss: 14.0929\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, checkpoint_callback]  # Include the checkpoint callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67005be6-6911-42fc-91c9-2b27a9115f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final Model\n",
    "model.save(\"cnn_model.h5\")\n",
    "print(\"✅ Final model saved as 'cnn_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efeed86-2962-4742-88fe-743c25bade7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-venv-312",
   "language": "python",
   "name": "global-venv-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
